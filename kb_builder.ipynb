{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c4ab1a-af36-448b-934b-1ad0cdfff90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Iterable, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9dae8ae-bbaf-4ed1-9be4-61e820c3fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional PDF support\n",
    "def extract_text(path: str) -> str:\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".txt\":\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read()\n",
    "    elif ext == \".pdf\":\n",
    "        try:\n",
    "            import PyPDF2  # type: ignore\n",
    "            text = []\n",
    "            with open(path, \"rb\") as f:\n",
    "                reader = PyPDF2.PdfReader(f)\n",
    "                for page in reader.pages:\n",
    "                    text.append(page.extract_text() or \"\")\n",
    "            return \"\\n\".join(text)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"PDF parsing failed. Install PyPDF2 or provide a .txt file.\") from e\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Provide .txt or .pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47615e3c-e15a-4570-9ece-e9f76a4c69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_whitespace(text: str) -> str:\n",
    "    return re.sub(r\"[ \\t]+\", \" \", re.sub(r\"\\r\\n|\\r\", \"\\n\", text)).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafb002b-9ff7-4e63-af24-628afc774a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_chars: int = 900, overlap: int = 120) -> List[str]:\n",
    "    \"\"\"Naive chunker by sentences, with overlap to preserve context.\"\"\"\n",
    "    # Split by paragraph/sentences\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+|\\n{2,}\", text)\n",
    "    chunks = []\n",
    "    cur = \"\"\n",
    "    for s in sentences:\n",
    "        if not s.strip():\n",
    "            continue\n",
    "        if len(cur) + len(s) + 1 <= max_chars:\n",
    "            cur = (cur + \" \" + s).strip()\n",
    "        else:\n",
    "            if cur:\n",
    "                chunks.append(cur)\n",
    "            # overlap: carry the tail\n",
    "            tail = cur[-overlap:] if overlap > 0 else \"\"\n",
    "            cur = (tail + \" \" + s).strip()\n",
    "    if cur:\n",
    "        chunks.append(cur)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fcf5e4b-cafe-4086-833e-56b8fc036f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very light-weight keyword tagger for privacy topics\n",
    "TOPIC_RULES = {\n",
    "    \"data_minimization\": [r\"\\bdata minimization\\b\", r\"\\bminimi[sz]e data\\b\"],\n",
    "    \"purpose_limitation\": [r\"\\bpurpose limitation\\b\", r\"\\bspecified, explicit and legitimate purposes\\b\"],\n",
    "    \"lawfulness\": [r\"\\blawful(ness)?\\b\", r\"\\blegal basis\\b\"],\n",
    "    \"accuracy\": [r\"\\baccuracy\\b\", r\"\\binaccurate data\\b\"],\n",
    "    \"storage_limitation\": [r\"\\bstorage limitation\\b\", r\"\\bretention\\b\"],\n",
    "    \"integrity_confidentiality\": [r\"\\bintegrity\\b\", r\"\\bconfidentiality\\b\", r\"\\bsecurity\\b\"],\n",
    "    \"data_subject_rights\": [r\"\\bdata subject\\b\", r\"\\bright of access\\b\", r\"\\berasure\\b\", r\"\\brectification\\b\"],\n",
    "    \"pii_identifiers\": [r\"\\bname\\b\", r\"\\bemail\\b\", r\"\\bphone\\b\", r\"\\baddress\\b\", r\"\\bid(entifier)?\\b\"],\n",
    "    \"high_risk_ai\": [r\"\\bhigh[- ]risk\\b\", r\"\\brisk management\\b\"],\n",
    "    \"transparency\": [r\"\\btransparen(t|cy)\\b\", r\"\\bexplainability\\b\"],\n",
    "    \"human_oversight\": [r\"\\bhuman oversight\\b\"],\n",
    "    \"data_governance\": [r\"\\bdata governance\\b\", r\"\\btraining, validation and testing\\b\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78ac91d-c7b4-41e0-b5a9-947a58900ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_chunk(text: str) -> List[str]:\n",
    "    tags = []\n",
    "    for topic, patterns in TOPIC_RULES.items():\n",
    "        if any(re.search(p, text, flags=re.IGNORECASE) for p in patterns):\n",
    "            tags.append(topic)\n",
    "    return tags or [\"misc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08cf3b78-ae9d-4d88-a74c-037ab032f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_summary(text: str, max_len: int = 240) -> str:\n",
    "    \"\"\"Simple extractive 'summary': take the first sentence up to max_len.\"\"\"\n",
    "    sent = re.split(r\"(?<=[.!?])\\s+\", text.strip())[0]\n",
    "    return (sent[:max_len] + (\"…\" if len(sent) > max_len else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14373281-80a6-46ca-a09d-665270168c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kb(doc_paths: Iterable[str], source_labels: Optional[Iterable[str]] = None,\n",
    "             out_jsonl: str = \"regulatory_kb.jsonl\",\n",
    "             max_chars: int = 900, overlap: int = 120) -> str:\n",
    "    if source_labels is None:\n",
    "        source_labels = [os.path.basename(p) for p in doc_paths]\n",
    "    records = []\n",
    "    for path, label in zip(doc_paths, source_labels):\n",
    "        raw = extract_text(path)\n",
    "        raw = normalize_whitespace(raw)\n",
    "        for idx, chunk in enumerate(chunk_text(raw, max_chars=max_chars, overlap=overlap)):\n",
    "            record = {\n",
    "                \"source\": label,\n",
    "                \"chunk_id\": f\"{label}:{idx:04d}\",\n",
    "                \"text\": chunk,\n",
    "                \"summary\": heuristic_summary(chunk),\n",
    "                \"tags\": tag_chunk(chunk)\n",
    "            }\n",
    "            records.append(record)\n",
    "    with open(out_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in records:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "    return os.path.abspath(out_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6616196f-e7a1-4b11-ab5e-f9f42d61666d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tools.kb_builder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterable\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkb_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_kb\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ✅ Jupyter에서는 직접 build_kb() 호출!\u001b[39;00m\n\u001b[32m      5\u001b[39m build_kb(\n\u001b[32m      6\u001b[39m     doc_paths=[\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdata/raw/EU_AI_act.txt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     overlap=\u001b[32m120\u001b[39m\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tools.kb_builder'"
     ]
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "from tools.kb_builder import build_kb\n",
    "\n",
    "# ✅ Jupyter에서는 직접 build_kb() 호출!\n",
    "build_kb(\n",
    "    doc_paths=[\n",
    "        \"data/raw/EU_AI_act.txt\",\n",
    "        \"data/raw/GDPR.txt\"\n",
    "    ],\n",
    "    out_jsonl=\"data/kb/regulatory_kb.jsonl\",\n",
    "    max_chars=900,\n",
    "    overlap=120\n",
    ")\n",
    "\n",
    "print(\"✅ KB 생성 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdad7f5-cbb2-4648-b21d-720559dea505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
